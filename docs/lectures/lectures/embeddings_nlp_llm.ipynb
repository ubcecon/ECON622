{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ECON622: Computational Economics with Data Science Applications\n",
        "\n",
        "Embeddings, NLP, and LLMs\n",
        "\n",
        "Jesse Perla (University of British Columbia)\n",
        "\n",
        "# Overview\n",
        "\n",
        "## Summary\n",
        "\n",
        "-   Relate embeddings to autoencoders and representation learning\n",
        "-   Discuss text and other embeddings\n",
        "-   Better discuss “out of distribution”, transfer learning, and fine\n",
        "    tuning\n",
        "-   Introduce self-supervised learning and semi-supervised learning\n",
        "-   Use the OpenAI and Hugging Face Packages\n",
        "-   Prepare to discuss attention and the transformer architecture and\n",
        "    foundation models in the next lecture\n",
        "\n",
        "## References\n",
        "\n",
        "-   These notes are a bare-bones introduction. See references for more\n",
        "-   See Mellisa Dell’s Survey [Deep Learning for\n",
        "    Economists](https://arxiv.org/abs/2407.15339) and\n",
        "    [Course](https://econdl.github.io/)\n",
        "    -   [Topic and Sentiment\n",
        "        Classification](https://econdl.github.io/intro/2023/03/22/lecture14.html)\n",
        "    -   [Semantic and Syntactic\n",
        "        Similarity](https://econdl.github.io/intro/2023/03/02/lecture11.html)\n",
        "-   [ProbML Book 1](https://probml.github.io/pml-book/book1.html) and\n",
        "    [ProbML Book 2](https://probml.github.io/pml-book/book2.html)\n",
        "\n",
        "## Packages\n",
        "\n",
        "Introducing new packages from OpenAI and Hugging Face"
      ],
      "id": "411f5d4b-8729-43ce-8a50-674b10381b12"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import transformers\n",
        "import torch\n",
        "from torch.nn.functional import cosine_similarity\n",
        "from openai import OpenAI\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel # Hugging Face\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "id": "eeea4731"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OpenAI\n",
        "\n",
        "-   Sign up for the [OpenAI Platform](https://platform.openai.com/)\n",
        "    -   Free for limited numbers of “tokens”\n",
        "-   Go to the `API keys` tab and create a key\n",
        "-   In your terminal, set `OPENAI_API_KEY` to this value (see\n",
        "    [here](https://platform.openai.com/docs/quickstart?desktop-os=macOS#create-and-export-an-api-key))\n",
        "\n",
        "# Is (Some) ML Just Fancy Logit?\n",
        "\n",
        "## Discrete Random Variables\n",
        "\n",
        "-   Up until now, we have mostly been interested in continuous outputs\n",
        "    from our models\n",
        "-   When working with NLP/etc. we usually have discrete outputs such as\n",
        "    a classification or prediction of the next “token”\n",
        "-   Lets review basic econometrics of logit and classification problems\n",
        "    and explain how they work with learned representations\n",
        "\n",
        "## Logit and Classification\n",
        "\n",
        "-   Logit takes observables $X$, a binary outcome $Y$ from some\n",
        "    population distribution and coefficients $\\beta$ $$\n",
        "    \\mathbb{P}(Y = 1 | X) = \\frac{\\exp(X\\cdot \\beta)}{1 + \\exp(X\\cdot \\beta)}\n",
        "    $$\n",
        "    -   In the background is a population distribution $\\mu^*$ over\n",
        "        $(Y,X)$\n",
        "    -   The parameters $\\beta$ are usually estimated with maximum\n",
        "        likelihood with samples from $\\mu^*$ (e.g., equivalent to ERM\n",
        "        for regression)\n",
        "    -   $X$ are handpicked observables, often transformed by economists\n",
        "        (e.g., “feature engineering” in ML-jargon)\n",
        "\n",
        "## Multinomial Logit\n",
        "\n",
        "-   More generally, with $K$ possible outcomes, we have a multinomial\n",
        "    logit model $$\n",
        "    \\mathbb{P}(Y = k | X) = \\frac{\\exp(X\\cdot \\beta_k)}{\\sum_{j=1}^K \\exp(X\\cdot \\beta_j)}\n",
        "    $$\n",
        "-   The $\\beta$ (matrix) are usually estimated with maximum\n",
        "    (log)-likelihood $$\n",
        "    \\min_{\\beta}\\left\\{- \\sum_{(X, y)\\in\\mathcal{D}} \\log \\mathbb{P}(Y = y | X;\\beta)\\right\\}\n",
        "    $$\n",
        "\n",
        "## Nesting Representations\n",
        "\n",
        "-   Often best to think of deep-learning as finding good representations\n",
        "    of the data, $\\phi : \\mathcal{X} \\to \\mathcal{Z}$ and then a thin\n",
        "    mapping or projection of that representation to an outcome space,\n",
        "    $\\hat{f} : \\mathcal{Z} \\to \\mathcal{Y}$\n",
        "-   With discrete-valued multinomial logit maps to distribution\n",
        "    $\\mathcal{Y}\\in\\mathbb{R}^K$ $$\n",
        "    \\mathbb{P}(Y = k | X;\\beta,\\theta) = \\frac{\\exp(\\phi(X;\\theta)\\cdot \\beta_k)}{\\sum_{j=1}^K \\exp(\\phi(X;\\theta)\\cdot \\beta_j)}\n",
        "    $$\n",
        "    -   Then MLE:\n",
        "        $\\min_{\\beta, \\theta} \\left\\{- \\sum_{(X, y)\\in\\mathcal{D}} \\log \\mathbb{P}(Y = y | X;\\beta, \\theta)\\right\\}$\n",
        "    -   As always, with ML we can just nest the $\\phi$ and $\\hat{f}$ in\n",
        "        the same function to jointly optimize all parameters\n",
        "\n",
        "## Turning “Features” to Probabilities\n",
        "\n",
        "-   Common to have a complicated internal approximation which they want\n",
        "    to convert to a discrete action/state/prediction/classification\n",
        "-   The easiest approach, pervasive in ML methods, is to convert this to\n",
        "    a probability distribution over discrete outcomes\n",
        "    -   “softmax”, i.e. the multinomial logit PMF, provides an easy way\n",
        "        to do this\n",
        "-   Among other reasons, this makes the objective’s differentiable and\n",
        "    allows for gradient-based optimization\n",
        "\n",
        "## Is ML Just Fancy Logit?\n",
        "\n",
        "-   At this point many economists will say that this all just sounds\n",
        "    like fancy logit\n",
        "    -   That is **mostly true**, for this type of problem\n",
        "    -   **But that is not insult!** Multinomial logit is a powerful, and\n",
        "        MLE is well understood. Logit/LLS/etc. are simple ML methods\n",
        "-   The key difference with deep learning + logit is important:\n",
        "    -   Economists typically work with engineered representations (e.g.,\n",
        "        taking logs, first-differences, variable selection)\n",
        "    -   But deep learning lets us use learned representations,\n",
        "        $\\phi(X;\\theta)$\n",
        "\n",
        "## Classic ML Approaches with LASSO\n",
        "\n",
        "-   Worth contrasting to a “classic” ML. If the “features/observables”\n",
        "    of $X$ are:\n",
        "    -   Assumed to map to the output probabilities linearly\n",
        "    -   Likely to overfit, or not be identified, by using irrelevant\n",
        "        features\n",
        "-   Then you can do things like a LASSO regularized multinomial logit $$\n",
        "    \\min_{\\beta} \\left\\{- \\sum_{(X, y)\\in\\mathcal{D}} \\log \\mathbb{P}(Y = y | X;\\beta) + \\lambda ||\\beta||_1\\right\\}\n",
        "    $$\n",
        "    -   i.e., penalize the 1-norm of the coefficients, which encourages\n",
        "        sparsity of $\\beta$ for $\\lambda > 0$. Deep Learning often\n",
        "        achieves this regularization indirectly (as discussed in the\n",
        "        Overparametrization lecture)\n",
        "\n",
        "## Terminology Differences\n",
        "\n",
        "-   Standard MLE loss in this setup is the “cross-entropy loss”\n",
        "-   The formula for the multinomial logit is called the “softmax”\n",
        "    function\n",
        "-   When thinking about the separate mapping of the representation to\n",
        "    the output, we often of it as the last layer\n",
        "-   And remember that we can have representations in the latent space:\n",
        "    -   If there are $N$ observables to predict $K$ outcomes, then in\n",
        "        multinomial logit we estimate $N \\times K$ parameters\n",
        "    -   But with representations, $z = \\phi(X;\\theta)$, it might be a\n",
        "        much higher (or lower) dimensional mapping to $K$ outcomes\n",
        "-   **Confusion**: “Inference” in some ML-speak is simply evaluating\n",
        "    $f(X)$\n",
        "\n",
        "# Embeddings\n",
        "\n",
        "## What is an Embedding?"
      ],
      "id": "52362b0a-f74a-4a52-a1ad-69bda9f553ea"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "output-location": "slide"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- An embedding is a numerical representation of data, typically in a continuous vector space, that captures semantic similarities and relationships between different pieces of information, such as words or images.\n",
            "  \n",
            "- In machine learning, embeddings are used to transform categorical variables into dense vectors, allowing algorithms to effectively process and understand high-dimensional and complex data."
          ]
        }
      ],
      "source": [
        "client = OpenAI()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You provide 2 short bullet points, technical answers.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"What is an embedding?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "id": "1f590d41"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Latent Space"
      ],
      "id": "c817a137-b7aa-429c-95e4-787883a1e3cb"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "output-location": "slide"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Embeddings often occupy latent spaces, which are learned representations that capture underlying structures and features of the data, facilitating tasks like clustering or classification.\n",
            "- The process of creating embeddings can be viewed as mapping the original high-dimensional data into a lower-dimensional latent space where similar items are closer together, enhancing interpretability and efficiency."
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You provide 2 short bullet points, technical answers.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"What is an embedding?\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": \"- An embedding is a dense vector representation of objects, such as words, sentences, or images, that captures semantic meanings and relationships in a continuous vector space.\\n- It transforms high-dimensional data into a lower-dimensional format while preserving essential properties, enabling easier computation in machine learning tasks.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\"content\": \"What is the relationship to latent spaces?\"\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "id": "613181f7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detour into OpenAI (others are similar)\n",
        "\n",
        "-   This is making calls to the OpenAI API.\n",
        "-   Three roles:\n",
        "    -   **system**: setup for the LLM to establish the persona, how to\n",
        "        respond, etc.\n",
        "    -   **user**: the question or prompt\n",
        "    -   **assistant**: the response\n",
        "-   Note that in a sequence of calculates, we give the entire history\n",
        "    including its own responses (tagged as `assistant`)\n",
        "-   We will come back to this shortly. Think of this as information for\n",
        "    conditioning.\n",
        "\n",
        "## Embeddings Overview\n",
        "\n",
        "-   Used loosely and inconsistently, but the spirit is the same\n",
        "-   A mapping of some $x \\in \\mathcal{X}$ to a latent space\n",
        "    $\\phi(x) \\in \\mathcal{Z}$\n",
        "-   Typically we want that $\\mathcal{Z}$ as a continuous vector space of\n",
        "    finite dimension\n",
        "    -   Crucially, we can think of distances in that space (e.g.,\n",
        "        $||\\phi(x) - \\phi(y)||$)\n",
        "-   The dimension of $\\mathcal{Z}$ may be smaller or larger than\n",
        "    $\\mathcal{X}$\n",
        "    -   If larger, typically embeddings of data $x \\in \\mu^*$ are close\n",
        "        to lower-dimensional manifold e.g., separating hyperplane in\n",
        "        $\\mathbf{R}^3$ with kernel\n",
        "-   Sometimes, as with network embeddings, want to preserve norms\n",
        "    -   e.g. if $||x - y||$ is small, then $||\\phi(x) - \\phi(y)||$ is\n",
        "        small\n",
        "\n",
        "## Inner Products Implicitly Define Norms (and Embeddings)\n",
        "\n",
        "-   As we saw with kernels, the embedding may be implicit in an inner\n",
        "    product\n",
        "-   Kernels induce norms without explicitly forming the feature map,\n",
        "    $\\phi(x)$, to the embedding space—which would be defined implicitly\n",
        "    by $K(x, x') = \\phi(x)^T \\phi(x')$.\n",
        "-   As discussed, the benefit of kernel methods is that the embedding\n",
        "    space may be infinite dimensional, but the kernel is finite\n",
        "    dimensional. The cost is we cannot directly map $x$ to the embedding\n",
        "    space\n",
        "\n",
        "## Cosine Similarity\n",
        "\n",
        "-   Canonical case of an inner product (with an associated norm, etc.)\n",
        "-   Cosine similarity is the “angle” between two vectors in the\n",
        "    embedding space $z = \\phi(x)$ and $z' = \\phi(x')$ $$\n",
        "    \\mathrm{sim}(z, z') = \\frac{z \\cdot z'}{||z|| ||z'||}\n",
        "    $$\n",
        "-   Interpretation: If $z$ and $z'$ are\n",
        "    1.  close in the embedding space, then the cosine similarity is\n",
        "        close to 1\n",
        "    2.  orthogonal, then the cosine similarity is 0\n",
        "    3.  opposite, then the cosine similarity is -1\n",
        "-   Norm comparison $||z - z'||$ instead? Works but not invariant to\n",
        "    scaling\n",
        "\n",
        "## Learned vs. Engineered Embeddings\n",
        "\n",
        "-   Embeddings are not related to a specific “supervised” goal, and\n",
        "    there may be many useful embeddings for a given data set\n",
        "-   We could engineer them (explicitly or implicitly).\n",
        "    -   e.g., count frequency of words in text, define implicitly\n",
        "        through a kernel\n",
        "-   Or we can use learn them\n",
        "    -   e.g., representation learning in a NN, PCA, etc.\n",
        "-   Recall that when we fit a neural network, $f(x) = \\hat{f}(\\phi(x))$,\n",
        "    we can think of $\\phi(x)$ as an embedding of $x$ in a latent space\n",
        "    mapped to output by a shallow $\\hat{f}$\n",
        "\n",
        "## Autoencoders and Compression\n",
        "\n",
        "-   One sense of “optimality” of embeddings is whether you can find a\n",
        "    representation which best compresses the data in a finite\n",
        "    dimensional latent space (or a higher-dimensional latent space with\n",
        "    a low-rank structure)\n",
        "-   This underlies the idea of using an Autoencoder. See [ProbML Book\n",
        "    1](https://probml.github.io/pml-book/book1.html) Section 20.3 and\n",
        "    [ProbML Book 2](https://probml.github.io/pml-book/book2.html)\n",
        "    Section 21\n",
        "-   The idea is to find functions which “encode” the data into a latent\n",
        "    space, and then “decode” it back to the original space\n",
        "\n",
        "## Autoencoders and Dimensionality Reduction\n",
        "\n",
        "-   General class of problems which they call auto-encoders in ML/data\n",
        "    science\n",
        "    -   Function $f$, the encoder, maps $X$ to a latent space $Z$, which\n",
        "        may be lower-dimensional\n",
        "    -   Function $g$, the decoder, maps points in the latent space $Z$\n",
        "        back to $X$\n",
        "    -   $\\theta_e$ and $\\theta_d$ are parameters for $f$ and $g$ which\n",
        "        we are trying to find\n",
        "-   Then the goal is to find the $\\theta_e$ and $\\theta_d$ parameters\n",
        "    for our encoder, $f$, and decoder, $g$, where for as many $X$ as\n",
        "    possible we have\n",
        "\n",
        "$$\n",
        "g(f(x; \\theta_e); \\theta_d) \\approx x\n",
        "$$\n",
        "\n",
        "-   The $z = f(x;\\theta_e)$ may or may not be lower-dimensional\n",
        "\n",
        "## Optimization Problem for an Autoencoder\n",
        "\n",
        "-   If we had a distribution for $x$ then can solve\n",
        "\n",
        "    $$\n",
        "    \\min_{\\theta_e, \\theta_d} \\mathbb{E}_{x\\sim \\mu^*}||g(f(x; \\theta_e); \\theta_d) - x||_2^2\n",
        "    $$\n",
        "\n",
        "-   Fit with ERM for $\\mathcal{D} \\sim \\mu^*$\n",
        "\n",
        "$$\n",
        "\\min_{\\theta_e, \\theta_d} \\frac{1}{|\\mathcal{D}|} \\sum_{x \\in \\mathcal{D}} ||g(f(x; \\theta_e); \\theta_d) - x||_2^2\n",
        "$$\n",
        "\n",
        "## PCA as the Optimal Linear Autoencoder\n",
        "\n",
        "-   Let $f(x) = W^T x$ and $g(z) = W z$ where\n",
        "    $W \\in \\mathbb{R}^{M \\times L}$. If $\\hat{x} \\approx W W^T x$,\n",
        "    “reconstruction error” is $||\\hat{x} - x||_2^2$.\n",
        "\n",
        "$$\n",
        "\\min_{W} \\frac{1}{N} \\sum_{n=1}^N ||W \\overbrace{W^T x_n}^{z_n = f(x_n;W)} - x_n||_2^2,\\quad \\text{with } W^T W = I\n",
        "$$\n",
        "\n",
        "# Word Embeddings\n",
        "\n",
        "## Tokens and Vocabulary\n",
        "\n",
        "-   Rather than trying to embed individual characters, it is usually\n",
        "    better to encode entire words (and, later, sentences, paragraphs,\n",
        "    text+images, etc.)\n",
        "-   If we decide on something that separates them, e.g. whitespace, then\n",
        "    we can map words to an integer index for each word\n",
        "-   Lets use a prebuilt tokenizer from Hugging Face. With a different\n",
        "    type of data (e.g., historical data) you may want to customize what\n",
        "    a “word” is"
      ],
      "id": "93fe4968-36bc-4d38-a06c-2f28aa2043d2"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "output-location": "slide"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', ',', 'hugging', 'face']\n",
            "[7592, 1010, 17662, 2227]"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokens = tokenizer.tokenize(\"hello, hugging face\")\n",
        "print(tokens)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(token_ids)"
      ],
      "id": "f46f583f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Token IDs to Embeddings\n",
        "\n",
        "-   The discrete values for the different words are not inherently\n",
        "    comparable\n",
        "-   An embedding will put them in a space where we can consider\n",
        "    similarity\n",
        "-   For now, lets use embedding from a prebuilt “model”"
      ],
      "id": "d52da0a6-a0ff-4672-af6e-01d13ff039d9"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([768])"
          ]
        }
      ],
      "source": [
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "def get_embedding(sentence):\n",
        "    tokens = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "        embeddings = outputs.last_hidden_state\n",
        "        # will see there are 3 total tokens, only middle is the sentence\n",
        "        return outputs.last_hidden_state[0,1:-1,:].squeeze()\n",
        "embed = get_embedding(\"hello\")\n",
        "print(embed.shape)"
      ],
      "id": "19c3fb55"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Similarity\n",
        "\n",
        "-   Measure distances in embedding space with cosine similarity or norms\n",
        "-   Because we are in higher-dimensions, there can be different reasons\n",
        "    for similarity. e.g., bank for money vs. the bank of a river, but\n",
        "    river and money are not as similar"
      ],
      "id": "a3862cf5-2803-4cf2-8852-977e4d09a96c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sim(bank, banks) = 0.743811845779419\n",
            "sim(bank, river) = 0.5635619163513184\n",
            "sim(bank, money) = 0.6932224035263062\n",
            "sim(river, money) = 0.5209330916404724"
          ]
        }
      ],
      "source": [
        "embed_bank = get_embedding(\"bank\")\n",
        "embed_banks = get_embedding(\"banks\")\n",
        "embed_river = get_embedding(\"river\")\n",
        "embed_money = get_embedding(\"money\")\n",
        "\n",
        "print(f\"sim(bank, banks) = {cosine_similarity(embed_bank, embed_banks, dim=0)}\")\n",
        "print(f\"sim(bank, river) = {cosine_similarity(embed_bank, embed_river, dim=0)}\")\n",
        "print(f\"sim(bank, money) = {cosine_similarity(embed_bank, embed_money, dim=0)}\")\n",
        "print(f\"sim(river, money) = {cosine_similarity(embed_river, embed_money, dim=0)}\")"
      ],
      "id": "ef5a4ee6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Where Did the Embedding Come From?\n",
        "\n",
        "-   As we will see below, `bert-base-uncased` is a model which can\n",
        "    predict missing words as its “supervised” goal,\n",
        "    $f(x) = \\hat{f}(\\phi(x))$\n",
        "-   This code just ripped off the $\\hat{f}(\\cdot)$ layers and use the\n",
        "    latent space $\\phi(x)$\n",
        "-   It is important to get a sense of how the representations were\n",
        "    learned - as they may not be appropriate for your task\n",
        "\n",
        "## Using OpenAI API"
      ],
      "id": "f9a5a308-0657-4396-830c-e468487500cc"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sim(bank, banks) = 0.7782837152481079\n",
            "sim(bank, river) = 0.4269741177558899\n",
            "sim(bank, money) = 0.4394051432609558\n",
            "sim(river, money) = 0.3747156262397766"
          ]
        }
      ],
      "source": [
        "def get_openai_embedding(sentence):\n",
        "  response = client.embeddings.create(input = [sentence], model=\"text-embedding-3-large\")\n",
        "  return torch.tensor(response.data[0].embedding)\n",
        "\n",
        "embed_bank = get_openai_embedding(\"bank\")\n",
        "embed_banks = get_openai_embedding(\"banks\")\n",
        "embed_river = get_openai_embedding(\"river\")\n",
        "embed_money = get_openai_embedding(\"money\")\n",
        "print(f\"sim(bank, banks) = {cosine_similarity(embed_bank, embed_banks, dim=0)}\")\n",
        "print(f\"sim(bank, river) = {cosine_similarity(embed_bank, embed_river, dim=0)}\")\n",
        "print(f\"sim(bank, money) = {cosine_similarity(embed_bank, embed_money, dim=0)}\")\n",
        "print(f\"sim(river, money) = {cosine_similarity(embed_river, embed_money, dim=0)}\")"
      ],
      "id": "59b07c1c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bigger Embeddings\n",
        "\n",
        "## Bag of Words\n",
        "\n",
        "-   Words usually occur in sentences, paragraphs, etc.\n",
        "-   Instead of embedding a single word, we can embed a block of text.\n",
        "-   Simple starting point: compare the relative frequency of words\n",
        "    1.  Turn the text into blocks of tokens with unique identifiers\n",
        "    2.  Filter out tokens that are not useful (e.g., “the”, “a”, etc.)\n",
        "    3.  Count the frequency of each token\n",
        "    4.  The embedding is the vector of the frequency of each token\n",
        "-   Many issues with this, but crucially it does not capture any sense\n",
        "    of context dependent meaning of words, and is invariant to word\n",
        "    order\n",
        "\n",
        "## Sentence Embeddings with LLMs\n",
        "\n",
        "-   Encode an entire sentence (i.e., a sequence of tokens) into a single\n",
        "    embedding and compare for similarity\n",
        "-   Since individual words are embedded, we just average for the\n",
        "    sentence"
      ],
      "id": "7e0b8a9e-7080-4110-9662-8f558856084e"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sim(e_1, e_2) = 0.8429715037345886\n",
            "sim(e_1, e_3) = 0.8270692229270935\n",
            "sim(e_2, e_3) = 0.9152544736862183"
          ]
        }
      ],
      "source": [
        "e_1 = get_embedding(\"The man bites the dog\").mean(dim=0)\n",
        "e_2 = get_embedding(\"The dog chased the man\").mean(dim=0)\n",
        "e_3 = get_embedding(\"The man was chased by the dog\").mean(dim=0)\n",
        "print(f\"sim(e_1, e_2) = {cosine_similarity(e_1, e_2, dim=0)}\")\n",
        "print(f\"sim(e_1, e_3) = {cosine_similarity(e_1, e_3, dim=0)}\")\n",
        "print(f\"sim(e_2, e_3) = {cosine_similarity(e_2, e_3, dim=0)}\")"
      ],
      "id": "b041f09e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Note that the 2nd and 3rd are the most similar, and the 1st and 3rd\n",
        "    the least.\n",
        "\n",
        "## What About the OpenAI API?"
      ],
      "id": "9fe1a982-8881-4409-a21d-07436f4b46b7"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sim(e_1, e_2) = 0.5414078831672668\n",
            "sim(e_1, e_3) = 0.5226691961288452\n",
            "sim(e_2, e_3) = 0.791109025478363"
          ]
        }
      ],
      "source": [
        "e_1 = get_openai_embedding(\"The man bites the dog\")\n",
        "e_2 = get_openai_embedding(\"The dog chased the man\")\n",
        "e_3 = get_openai_embedding(\"The man was chased by the dog\")\n",
        "print(f\"sim(e_1, e_2) = {cosine_similarity(e_1, e_2, dim=0)}\")\n",
        "print(f\"sim(e_1, e_3) = {cosine_similarity(e_1, e_3, dim=0)}\")\n",
        "print(f\"sim(e_2, e_3) = {cosine_similarity(e_2, e_3, dim=0)}\")"
      ],
      "id": "d17f8327"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Same ordering. A good sign.\n",
        "\n",
        "## Be Cautious, Interpretation is Tricky"
      ],
      "id": "ec797452-073a-4a4f-807c-b9ebf2d484d4"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sim(e_1, e_2) = 0.5413370728492737\n",
            "sim(e_1, e_3) = 0.5225977897644043\n",
            "sim(e_2, e_3) = 0.7911193370819092\n",
            "sim(e_3, e_4) = 0.8597935438156128"
          ]
        }
      ],
      "source": [
        "e_1 = get_openai_embedding(\"The man bites the dog\")\n",
        "e_2 = get_openai_embedding(\"The dog chased the man\")\n",
        "e_3 = get_openai_embedding(\"The man was chased by the dog\")\n",
        "e_4 = get_openai_embedding(\"The man chased the dog\")\n",
        "print(f\"sim(e_1, e_2) = {cosine_similarity(e_1, e_2, dim=0)}\")\n",
        "print(f\"sim(e_1, e_3) = {cosine_similarity(e_1, e_3, dim=0)}\")\n",
        "print(f\"sim(e_2, e_3) = {cosine_similarity(e_2, e_3, dim=0)}\")\n",
        "print(f\"sim(e_3, e_4) = {cosine_similarity(e_3, e_4, dim=0)}\")"
      ],
      "id": "4913c2e5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Note that `sim(e_3, e_4) > sim(e_3, e_2)` even though they they seem\n",
        "    to have the exact opposite meaning!\n",
        "-   Why? There are many embeddings (e.g. bag of words) which make these\n",
        "    close, and others where they are far apart. Hard to know without a\n",
        "    sense of how it was trained.\n",
        "\n",
        "## Clustering\n",
        "\n",
        "-   Since embeddings provide a measure of similarity/distance, we can\n",
        "    cluster it into groups or use other tools to find interpretations\n",
        "-   There are various algorithms to cluster based on representations,\n",
        "    and find the closest elements within the set of data for a new\n",
        "    element\n",
        "-   One approach: come up with a lower-dimensional embedding which\n",
        "    preserves norms, as in [t-SNE (t-Distributed Stochastic Neighbor\n",
        "    Embedding)](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n",
        "    -   i.e., find a $h(\\cdot)$ such that if $||x - y||$ is small, then\n",
        "        \\|\\|$h(x) - h(y)||$ is small\n",
        "    -   Generally better than k-means, etc. for this kind of problem,\n",
        "        and allows you to project to 2 or 3 dimensional embeddings, not\n",
        "        just discrete values\n",
        "\n",
        "## Get Some Random Embeddings"
      ],
      "id": "eb664a9c-e287-4821-9d7a-a00f878fdaa2"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model has 30522 tokens\n",
            "model has 24690 full tokens (e.g. not special symbols, special tokens, etc.)"
          ]
        }
      ],
      "source": [
        "vocab = tokenizer.get_vocab()\n",
        "tokens = list(vocab.keys())\n",
        "print(f\"model has {len(tokens)} tokens\")\n",
        "special_tokens = ['##', '[MASK]', '[CLS]', '[SEP]', '[PAD]']\n",
        "full_tokens = [token for token in tokens if not token.startswith('##') and token not in special_tokens]\n",
        "print(f\"model has {len(full_tokens)} full tokens (e.g. not special symbols, special tokens, etc.)\")\n",
        "sampled_tokens = np.random.choice(full_tokens, size=50, replace=False)\n",
        "token_ids = [vocab[token] for token in sampled_tokens]\n",
        "with torch.no_grad():\n",
        "    embeddings = model.embeddings.word_embeddings(torch.tensor(token_ids))"
      ],
      "id": "13a707db"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize with t-SNE"
      ],
      "id": "b441d6fd-7d86-4dc7-86c4-4f83b2d26d13"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "output-location": "slide"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHBCAYAAAAhAWw4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nAAAAAElFTkSuQmCC\n"
          }
        }
      ],
      "source": [
        "tsne = TSNE(n_components=2, random_state=0) # approx with 2 dim embedding\n",
        "embeddings_2d = tsne.fit_transform(embeddings.numpy())\n",
        "# Plot the t-SNE results\n",
        "plt.figure()\n",
        "for i, token in enumerate(sampled_tokens):\n",
        "    x, y = embeddings_2d[i]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+0.1, y+0.1, token, fontsize=9)\n",
        "plt.title('t-SNE visualization of BERT token embeddings')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.show()"
      ],
      "id": "e11319c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lowering the Embedding Dimension\n",
        "\n",
        "-   As discussed, t-SNE is one way to project down to something\n",
        "    visualizable\n",
        "-   More generally, though, you can find a lower-rank approximation to\n",
        "    the embedding space\n",
        "-   With some APIs,\n",
        "    (e.g. [OpenAI](https://platform.openai.com/docs/guides/embeddings/))\n",
        "    they make this especially easy\n",
        "    -   In particular, you can simply drop digits of precision on the\n",
        "        embedding to make it coarser, following [this\n",
        "        paper](https://arxiv.org/abs/2205.13147)\n",
        "    -   See OpenAI docs for more details. Can [do this\n",
        "        automatically](https://platform.openai.com/docs/api-reference/embeddings/create)\n",
        "        by passing `dimensions`\n",
        "\n",
        "## Classification\n",
        "\n",
        "-   For classification tasks, we can use this embedding with\n",
        "    representation learning and softmax (i.e., logit likelihood)\n",
        "-   One strategy for classification\n",
        "    1.  Embed sentences\n",
        "    2.  Use some nonlinear transformations (e.g., NN) to get a\n",
        "        representation of the embedding\n",
        "    3.  Use a “softmax” to get a probability distribution over the\n",
        "        classes\n",
        "    4.  Fit with MLE as a “supervised” (multinormal logit) problem\n",
        "-   Others use embeddings as inputs to different classification\n",
        "    algorithms (e.g. [OpenAI random forest\n",
        "    example](https://cookbook.openai.com/examples/classification_using_embeddings))\n",
        "\n",
        "## Multi-Modal Embeddings\n",
        "\n",
        "-   Embeddings can be used for more than just text\n",
        "-   Images, audio, etc. can all be embedded\n",
        "-   The key is to have a representation which is useful for the task at\n",
        "    hand\n",
        "-   For example, we can embed text and images together to predict the\n",
        "    sentiment of a review\n",
        "\n",
        "## Aligning Embeddings\n",
        "\n",
        "-   Loosely, if you have related data on the same entities (e.g., labels\n",
        "    on images) then you can work to align the embeddings of both\n",
        "    -   e.g., a $\\phi_1(X_{\\text{image}})$ and $\\phi_2(X_{\\text{text}})$\n",
        "        similar if the text describes the image\n",
        "    -   Then you can attempt to get the $\\phi_1$ and $\\phi_2$ to be\n",
        "        similar for that data\n",
        "    -   If so, then you can map back and forth between image and text in\n",
        "        the embedding space (i.e., take text, map to $\\phi_2$ to the\n",
        "        embedding space, then map back form the embedding to the image\n",
        "        space)\n",
        "-   See Melissa Dell’s [Multimodel\n",
        "    Learning](https://econdl.github.io/intro/2023/02/28/lecture10.html).\n",
        "    Complicated in practice (e.g., [contrastive\n",
        "    learning](https://econdl.github.io/intro/2023/02/23/lecture8.html))\n",
        "-   See [OpenAI’s multimodel example with\n",
        "    CLIP](https://huggingface.co/learn/cookbook/en/faiss_with_hf_datasets_and_clip)\n",
        "    for an example\n",
        "\n",
        "# Sequential Data and Token Prediction\n",
        "\n",
        "## Distribution of “Tokens”\n",
        "\n",
        "-   In many cases, data has an inherent sequential ordering. e.g. time\n",
        "    series, language, etc.\n",
        "-   Consider conditional probabilities over $x_t \\in \\mathcal{X}$ which\n",
        "    is discrete set of outcomes $k = 1, \\ldots K$. Generically call\n",
        "    these “tokens”\n",
        "-   Objects of interest: for $x_1, x_2, \\ldots, x_T$ for a sequence of\n",
        "    length $T$, have a “population distribution” ,\n",
        "    $\\{x_1, \\ldots, x_T\\} \\sim \\mu^*$\n",
        "-   We may want to condition on the past to predict the next token,\n",
        "    condition on the entire sequence to predict missing ones, etc.\n",
        "\n",
        "## Token Prediction from Conditional Probabilities\n",
        "\n",
        "-   Given a sequence $x_1, x_2, \\ldots, x_{t-1}$, model the conditional\n",
        "    distribution: $$\n",
        "    \\mathbb{P}(x_t | x_{t-1}, x_{t-2}, \\ldots, x_1)\n",
        "    $$\n",
        "    -   Where in the background these are done with marginal and\n",
        "        conditional probabilities sampling the population distribution\n",
        "        $\\mu^*$\n",
        "-   Basic strategy (details on “transformers” after we see how to use\n",
        "    them):\n",
        "    1.  Do an embedding for each token $\\phi_1(x_t)$\n",
        "    2.  Map those embeddings to some combined representation,\n",
        "        $\\phi_2(\\phi_1(x_1), \\ldots, \\phi_1(x_{t-1}))$\n",
        "    3.  Map that with “softmax” to get probabilities over\n",
        "        $k = 1, \\ldots, K$ for $x_t$\n",
        "    4.  Fit with MLE as a “supervised” (multinormal logit) problem\n",
        "\n",
        "## Provide Conditioning Tokens in the Prompt\n",
        "\n",
        "-   See Melissa Dell’s\n",
        "    [Prompting](https://www.dropbox.com/scl/fi/e8rnp61e9mv6es455f91c/lecture_prompting.pdf?rlkey=8mj1y59l3tjod34tp5vgk8akv&e=1&dl=0)\n",
        "    lecture, Hugging Face’s\n",
        "    [docs](https://huggingface.co/docs/transformers/en/tasks/prompting)\n",
        "    and [Prompts for\n",
        "    Economists](https://sites.google.com/view/lastunen/ai-for-economists?authuser=0)"
      ],
      "id": "a0f59587-bb7f-42f2-bd9a-94f366d637e5"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "output-location": "slide"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- An embedding is a mathematical representation of discrete objects (like words, sentences, or images) in a continuous vector space, enabling machine learning models to capture semantic relationships and similarities.\n",
            "- Common techniques for generating embeddings include Word2Vec, GloVe, and deep learning models such as BERT, which leverage neural networks to create high-dimensional representations."
          ]
        }
      ],
      "source": [
        "client = OpenAI()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.7, # higher temperature adds \"entropy\"\n",
        "    messages=[\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You provide 2 short bullet points, technical answers.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"What is an embedding?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "id": "167d2383"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concatenating Results"
      ],
      "id": "269df9ce-9842-4ade-b3ee-aba2432656f1"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "output-location": "slide"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Embeddings can be considered as specific types of representations within a latent space, where the latent space itself is an abstract, lower-dimensional space that captures essential features of high-dimensional data.\n",
            "- The process of creating embeddings involves mapping input data into the latent space, allowing for efficient similarity comparisons and transformations while retaining meaningful relationships."
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You provide 2 short bullet points, technical answers.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"What is an embedding?\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": \"- An embedding is a dense vector representation of objects, such as words, sentences, or images, that captures semantic meanings and relationships in a continuous vector space.\\n- It transforms high-dimensional data into a lower-dimensional format while preserving essential properties, enabling easier computation in machine learning tasks.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\"content\": \"What is the relationship to latent spaces?\"\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "id": "65d90f90"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mental Model of Sequential Generation\n",
        "\n",
        "1.  Start with a set of tokens, $x_1, x_2, \\ldots, x_{t-1}$ (include\n",
        "    **EVERYTHING**)\n",
        "2.  Condition on those tokens to find the\n",
        "    $\\mathbb{P}(x_t | x_{t-1}, x_{t-2}, \\ldots, x_1)$ distribution\n",
        "3.  Sample from that to get the $x_t$ token\n",
        "    -   “Temperature” settings increases/decreases the entropy of\n",
        "        $\\mathbb{P}(x_t | \\cdot)$ artificially to encourage/discourage\n",
        "        randomness\n",
        "4.  Add its own generated token to the set of tokens,\n",
        "    $x_1, x_2, \\ldots, x_{t-1}, x_t$\n",
        "5.  Condition on those tokens to find the\n",
        "    $\\mathbb{P}(x_{t+1} | x_t, x_{t-1}, \\ldots, x_1)$ distribution\n",
        "6.  Repeat until it hits a special “done” token (itself predicted) or\n",
        "    reaches a maximum length\n",
        "\n",
        "## Cardinality of the Estimated Conditional Distribution\n",
        "\n",
        "-   ChatGPT and others generate text token-by-token auto-regressively\n",
        "-   No Markov assumptions. $K^T$ possible sequences of $K$ tokens of\n",
        "    length $T$\n",
        "-   GPT3-ish sized LLMs support roughly $T=4,000$ with $K=50,000$ tokens\n",
        "    -   Estimating a\n",
        "        $\\mathbb{P} : 50,000 \\times 50,000^{4,000}\\to [0,1]$ conditional\n",
        "        PMF\n",
        "    -   And growing. GPT4o supports $128k$ tokens for context (i.e.,\n",
        "        conditioning) and $16k$ for “output”\n",
        "\n",
        "## How Can This Possibly Work?\n",
        "\n",
        "-   It sometimes feels like it has compressed and memorized the entire\n",
        "    internet\n",
        "-   We don’t always know the parameterization or number of tokens in the\n",
        "    training data (remember, this largely uses MLE to train) but\n",
        "    OpenAI’s GPT-3 was disclosed\n",
        "    -   The $\\mathbb{P}(\\cdot | \\cdot)$ is approximated by approximating\n",
        "        175 billion parameters\n",
        "    -   Trained on 300 billion tokens from close to a terrabyte of\n",
        "        cleaned text\n",
        "-   Which is **absurdly small amount of data** given the cardinality of\n",
        "    $\\mathbb{P}$\n",
        "    -   Paraphrasing Mikhail Belkin: this is like estimating the library\n",
        "        of congress with a molecule of ink.\n",
        "    -   If the curse-of-dimensionality was the constraint, data would\n",
        "        need to grow exponentially as $T$ increases. It doesn’t.\n",
        "\n",
        "# Training\n",
        "\n",
        "## Manifold Hypothesis + Engineering Heroics?\n",
        "\n",
        "-   Plenty of interpretations for how this is possible, but a few key\n",
        "    ones:\n",
        "    1.  The Manifold Hypothesis, as we discussed in the Deep Learning\n",
        "        lecture.\n",
        "        -   Given the right “representation”, human knowledge is far\n",
        "            simpler than it appears. Knowledge is easily compressible\n",
        "            since it has an inherent order independent of language\n",
        "    2.  Implicit and explicit regularization of various forms avoids\n",
        "        overfitting\n",
        "    3.  The “Transformer”, a masterpiece of modern engineering we will\n",
        "        discuss in our next lecture\n",
        "\n",
        "## More than MLE\n",
        "\n",
        "-   While the lion’s share of this training may have been just sequently\n",
        "    predicting the next token for the data distribution, more is done in\n",
        "    practice.\n",
        "-   e.g., “AI Alignment” which tries to encourage these models to\n",
        "    capture socially desirable properties\n",
        "    -   Encourage $\\mathbb{P}$ to be less racist or safer than the\n",
        "        underlying training data by penalizing certain outcomes\n",
        "    -   Add rewards based on human labeled data\n",
        "    -   Distorting the $\\mu^*$ that you don’t want it to train with to\n",
        "        ensure safety\n",
        "-   Reinforcement Learning from Human Feedback (RLHF). e.g. data from\n",
        "    flagging an answer (good vs. bad) to help encourage good solutions\n",
        "-   And much more. An enormous undertaking for a big LLM.\n",
        "\n",
        "## Good Representations Are Reusable!\n",
        "\n",
        "-   As always, good representations tend to be useful for many tasks\n",
        "-   This goes both ways. Can use\n",
        "    -   Different tasks an be used to refine the representations used\n",
        "        for sequential prediction, even if not our primary goal\n",
        "    -   Representations trained for LLMs for tasks which have nothing to\n",
        "        do with their original training\n",
        "-   Crudely, can train a $f(x) = \\hat{f}(\\phi(x))$ and swap out the\n",
        "    $\\hat{f}$, or distort the $\\hat{f}$ to provide artificial incentives\n",
        "    to encourage good $\\phi(\\cdot)$\n",
        "-   Whenever possible, start fitting a deep learning approximation from\n",
        "    a previously trained one <!-- \n",
        "    ## Good Representations are Transferable\n",
        "    - Remember: with most ML methods, the unsupervised part (e.g., learning the $\\phi(\\cdot)$ is most of the work)\n",
        "    - We have good generalization performance when the representations are especially strong\n",
        "    - Keep in mind that ML is being fit (e.g., with MLE) with a population distribution $\\mu^*$ fixed.\n",
        "      - If we are using a different distribution, we need to be careful!  Even for the same tasks\n",
        "      - One option: refine our problem by helping it specialize\n",
        "      - Another: provide more information (e.g. tokens) to condition on  -->\n",
        "\n",
        "## Using “Unlabelled” Data\n",
        "\n",
        "-   In many cases, we have a lot of data, but only a small amount of\n",
        "    labeled data (i.e., with outcomes)\n",
        "-   For example, there are many images, but we only have a few with\n",
        "    human-coded descriptions\n",
        "-   Or we have a large number of examples of text for monetary policy\n",
        "    statements, but only a few with human-coded sentiment or outcomes\n",
        "-   Given that most of the work in deep learning is finding the\n",
        "    $\\phi(\\cdot)$, how can we use the data itself to improve the\n",
        "    representations - which will hopefully improve the model for many\n",
        "    downstream tasks?\n",
        "\n",
        "## Semi-Supervised Learning\n",
        "\n",
        "-   **Semi-supervised learning** combines a small amount of labeled data\n",
        "    with a larger set of unlabeled data to improve model performance by\n",
        "    leveraging the structure in the unlabeled data.\n",
        "-   e.g., “Augment” data by adding noise, rotating images, for the\n",
        "    labeled data we do have. This will add regularization, encourage\n",
        "    important sources of representations (e.g., invariance to\n",
        "    permutations)\n",
        "\n",
        "## Self-Supervised learning\n",
        "\n",
        "-   **Self-supervised learning** is a form of unsupervised learning\n",
        "    where the model generates pseudo-labels or tasks from unlabeled data\n",
        "    itself to learn useful representations without relying on external\n",
        "    labels.\n",
        "-   e.g., mask out some words and predict them, mask out time-series\n",
        "    data to predict the missing values, etc.\n",
        "-   See more in [general\n",
        "    surveys](https://ieeexplore.ieee.org/abstract/document/10559458) and\n",
        "    ones on [contrastive\n",
        "    vs. generative](https://ieeexplore.ieee.org/abstract/document/9462394)\n",
        "\n",
        "## Contrastive Learning\n",
        "\n",
        "-   **Contrastive learning** is a form of self-supervised learning where\n",
        "    the model is encouraged to keep the representations of similar data\n",
        "    close, and dissimilar data further away.\n",
        "-   For example, with a batch of sentences, predict the next token for\n",
        "    the sentence, but also try to predict the next token of the OTHER\n",
        "    sentences in the loss (which should be unrelated/constrastive)\n",
        "    -   This encourages the model to learn the importance of context.\n",
        "        See [SimCSE](https://arxiv.org/abs/2104.08821)\n",
        "\n",
        "# Classification and Masking\n",
        "\n",
        "## Hugging Face\n",
        "\n",
        "-   Hugging Face provides a simple interface to many prebuilt\n",
        "    transformer models, datasets, etc.\n",
        "-   We can use these for predicting the next token, but also tasks like\n",
        "    sentiment analysis, filling in missing tokens, etc.\n",
        "-   Unlike the OpenAI API, we can download the models and use them\n",
        "    locally, “fine-tune” them, etc.\n",
        "-   See [Quick Tour](https://huggingface.co/docs/transformers/quicktour)\n",
        "    for more\n",
        "\n",
        "## Pipelines\n",
        "\n",
        "-   The `pipeline` function in Hugging Face is a simple way to use\n",
        "    prebuilt models for common tasks. See the [pipeline\n",
        "    tutorial](https://huggingface.co/docs/transformers/main/en/pipeline_tutorial)\n",
        "-   Loads pretrained models from public repositories"
      ],
      "id": "91dd9749-5e18-4c8f-a197-97bec9eb93f0"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model)."
          ]
        }
      ],
      "source": [
        "classifier = pipeline(\"sentiment-analysis\") # defaults to a model\n",
        "fill_masker = pipeline(model=\"google-bert/bert-base-uncased\") # device=0) # to use GPU   "
      ],
      "id": "0f8e808b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sentiment Analysis (defaults to “Positive” or “Negative”)\n",
        "\n",
        "-   Defaulted to\n",
        "    `distilbert/distilbert-base-uncased-finetuned-sst-2-english`"
      ],
      "id": "826dbe3d-283f-462e-b1b0-7829dad1de97"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9998424053192139}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9997472167015076}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9997096657752991}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9587399363517761}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.845471978187561}]"
          ]
        }
      ],
      "source": [
        "print(classifier(\"Transformers library is great.\"))\n",
        "print(classifier(\"Transformers library is awful.\"))\n",
        "print(classifier(\"I am ok with the transformers.\"))\n",
        "print(classifier(\"Transformers are a toy from the 80s.\"))\n",
        "print(classifier(\"The chicken crossed the road.\"))"
      ],
      "id": "aa6c2f4d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Not bad. But why is that `toy from the 80s` overwhelmingly positive,\n",
        "    and `chicken crossed the road` moderately negative?\n",
        "\n",
        "## Fill Masked\n",
        "\n",
        "-   Finds\n",
        "    $\\mathbb{P}(x_t | x_T, x_{T-1}, \\ldots x_{t+1}, x_{t-1}, x_{t-2}, \\ldots, x_1)$\n",
        "-   Some, like\n",
        "    [BERT](https://huggingface.co/nlpaueb/legal-bert-base-uncased), were\n",
        "    trained for this direct task\n",
        "-   Often done with a special `[MASK]` token"
      ],
      "id": "73ce0a1e-4876-43ca-9ca6-3ac1950e94a1"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "output-location": "column"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "[{'score': 0.04227157309651375,\n",
              "  'token': 3291,\n",
              "  'token_str': 'problem',\n",
              "  'sequence': 'this is a simple problem.'},\n",
              " {'score': 0.03105001524090767,\n",
              "  'token': 3160,\n",
              "  'token_str': 'question',\n",
              "  'sequence': 'this is a simple question.'},\n",
              " {'score': 0.029722511768341064,\n",
              "  'token': 8522,\n",
              "  'token_str': 'equation',\n",
              "  'sequence': 'this is a simple equation.'}]"
            ]
          }
        }
      ],
      "source": [
        "fill_masker(\"This is a simple [MASK].\",\n",
        "            top_k=3) # 3 highest probability"
      ],
      "id": "47ca1434"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-Tuning\n",
        "\n",
        "## Remember the Population Distribution!\n",
        "\n",
        "-   The training was all done with a fixed population distribution\n",
        "    $\\mu^*$\n",
        "-   If our population distribution is distributed differently, we need\n",
        "    to be careful\n",
        "-   Maybe we can condition on tokens appropriately, that we can align\n",
        "    the conditional distribution (implicitly from $\\mu^*$). Useful but\n",
        "    success not guaranteed\n",
        "-   Alternatively, we can specialize the model to our problem. Have\n",
        "    specialized tokens, different emphasis in the text, etc.\n",
        "    -   [Hugging Face provided pre-trained\n",
        "        models](https://huggingface.co/?activityType=update-model&feedType=following)\n",
        "        which are a good starting point for various domains, etc.\n",
        "-   Even with the same $\\mu^*$, perhaps the prebuilt representations are\n",
        "    not ideal for our particular task. May need to tweak representations\n",
        "    to improve the task\n",
        "\n",
        "## No-Shot and Few-Shot Learning\n",
        "\n",
        "-   When they talk about “no-shot” or “few-shot” learning in ML, they\n",
        "    are thinking of using a prebuilt representation for a task almost as\n",
        "    is (e.g., a new task $\\hat{f}_2(\\phi(x))$ given trained\n",
        "    $\\hat{f}_1(\\phi(x))$) either with only minimal changes to\n",
        "    $\\hat{f}_2$ or none at all.\n",
        "    -   Could remove the last layer and training with a few samples\n",
        "-   Alternatively, since LLMs can handle rich conditioning information\n",
        "    (including text descriptions and examples in the $x_1, \\ldots x_T$)\n",
        "    you might be able to give the examples for the “task” in the prompt\n",
        "    itself and not actually train anything\n",
        "-   This works often in practice, but requires tweaking to ensure the\n",
        "    tokens for conditioning (i.e. the prompt) is appropriate\n",
        "\n",
        "## Fine-Tuning\n",
        "\n",
        "-   Other times, you want to take a pre-built model and do additional\n",
        "    training to better align it with your population distribution or\n",
        "    task.\n",
        "-   If you just want to specialize the output, but leave the\n",
        "    representations intact, then you may want to “freeze” the parameters\n",
        "    for every layer except the last few (i.e., the $\\hat{f}$\n",
        "    parameters), or swap out the functional form entirely.\n",
        "    -   You will see this referred to as\n",
        "        [“freezing”](https://flax-linen.readthedocs.io/en/latest/guides/training_techniques/transfer_learning.html#optax-multi-transform)\n",
        "        layers\n",
        "    -   More generally, changing existing trained models is called\n",
        "        [“model\n",
        "        surgery”](https://flax.readthedocs.io/en/latest/guides/surgery.html)\n",
        "\n",
        "## Hugging Face Example\n",
        "\n",
        "-   See [hugging face\n",
        "    docs](https://huggingface.co/docs/transformers/en/training) with\n",
        "    [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/training.ipynb)\n",
        "    -   Downloads a pre-built LLM\n",
        "    -   Downloads Yelp Reviews data\n",
        "    -   Swaps out the last classification layer\n",
        "    -   Trained to predict the number of stars for the Yelp review  \n",
        "-   [Open AI Fine\n",
        "    tuning](https://platform.openai.com/docs/guides/fine-tuning/) is\n",
        "    harder since it does not store the model locally\n",
        "    -   On the other hand, because it runs on OpenAI servers it may be\n",
        "        faster (albeit costs money)\n",
        "    -   See other examples in the [Open AI\n",
        "        Cookbook](https://cookbook.openai.com/)"
      ],
      "id": "e9a0f510-66b5-4f84-93b0-6c48d1dbb249"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  }
}